{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f32e958-6722-4aa3-99ee-ec8a8c0fd591",
   "metadata": {},
   "source": [
    "## Ejemplo de las valoraciones de un restaurante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12173585-32af-406c-bf47-53fb06c84ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "      <th>meal_time</th>\n",
       "      <th>tip_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good food good service.</td>\n",
       "      <td>5</td>\n",
       "      <td>dinner</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good food with friendly service.</td>\n",
       "      <td>4</td>\n",
       "      <td>lunch</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average food and bad service</td>\n",
       "      <td>2</td>\n",
       "      <td>breakfirst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review  star   meal_time  tip_%\n",
       "0           Good food good service.     5      dinner   0.25\n",
       "1  Good food with friendly service.     4       lunch   0.18\n",
       "2      Average food and bad service     2  breakfirst    NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Create a small sample dataset\n",
    "X_train = pd.DataFrame(data={'review': ['Good food good service.', \n",
    "                                        'Good food with friendly service.',\n",
    "                                        'Average food and bad service'],\n",
    "                             'star': [5,4,2],\n",
    "                             'meal_time': ['dinner','lunch','breakfirst'],\n",
    "                             'tip_%': [0.25, 0.18, np.nan]})\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c5097-5963-4a18-ba93-c66276a65b2e",
   "metadata": {},
   "source": [
    "### Construimos un ColumTransformer\n",
    "\n",
    "1. For the categorical column meal_time, encode it using OneHotEncoder\n",
    "2. For numeric columns star and tip_%, create a Pipeline to first impute NaN values using SimpleImputer and then scale its result using MinMaxScaler\n",
    "3. Pass through the remaining columns (review)\n",
    "4. Combine the two results together using ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ee56c9-8a97-4293-bf85-95a984aaa253",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m num_pipe = Pipeline([\n\u001b[32m      6\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcomputer\u001b[39m\u001b[33m'\u001b[39m,SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m'\u001b[39m, fill_value=\u001b[32m0\u001b[39m)),\n\u001b[32m      7\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m, MinMaxScaler())\n\u001b[32m      8\u001b[39m ])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# construct the ColumnTransformer\u001b[39;00m\n\u001b[32m     11\u001b[39m ColumnTransformation = ColumnTransformer(\n\u001b[32m     12\u001b[39m     transformers=[\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m# one-hot encode categorical cols \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mcat_ohe\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m, cat_col),\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# pipe transform numeric cols\u001b[39;00m\n\u001b[32m     16\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mnum_pipe\u001b[39m\u001b[33m'\u001b[39m, num_pipe, num_col)\n\u001b[32m     17\u001b[39m     ]\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# passthrough the rest cols\u001b[39;00m\n\u001b[32m     19\u001b[39m     , remainder = \u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# fit and transform the data\u001b[39;00m\n\u001b[32m     23\u001b[39m ColumnTransformation.fit_transform(X_train)\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "cat_col = ['meal_time']\n",
    "num_col = ['star','tip_%']\n",
    "\n",
    "# make a pipeline to do computing and scaling\n",
    "num_pipe = Pipeline([\n",
    "    ('computer',SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# construct the ColumnTransformer\n",
    "ColumnTransformation = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # one-hot encode categorical cols \n",
    "        ('cat_ohe', OneHotEncoder(sparse_output = False, handle_unknown='ignore'), cat_col),\n",
    "        # pipe transform numeric cols\n",
    "        ('num_pipe', num_pipe, num_col)\n",
    "    ]\n",
    "        # passthrough the rest cols\n",
    "    , remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "# fit and transform the data\n",
    "ColumnTransformation.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a7040-29b2-406c-8ee3-35b3e5a9ffc0",
   "metadata": {},
   "source": [
    "## Scikit-Learn ColumnTransformer\n",
    "Extraído de la [web](https://gist.github.com/iamirmasoud/03b8788e87768691103784af9767cbd8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7c2885c4-4d9b-4471-a92f-ff132351598b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>38.07</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.65</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>30.46</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>10.63</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18.35</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill smoker  day    time  size\n",
       "112       38.07     No  Sun  Dinner   3.0\n",
       "19        20.65     No  NaN  Dinner   NaN\n",
       "187       30.46    Yes  NaN  Dinner   NaN\n",
       "169       10.63    Yes  Sat  Dinner   2.0\n",
       "31        18.35     No  NaN  Dinner   NaN"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seaborn import load_dataset\n",
    "#Set seed\n",
    "seed = 123\n",
    "\n",
    "#Loading data sets\n",
    "df = load_dataset('tips').drop(columns=['tip', 'sex']).sample(n=5, random_state=seed)\n",
    " \n",
    "#Add missing values\n",
    "df.iloc[[1, 2, 4], [2, 4]] = np.nan\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "952a5cd7-b159-4d30-b1b6-4e6985399cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns are: ['smoker', 'day', 'time']\n",
      "Numerical columns are: ['size']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Partition data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['total_bill']),\n",
    "                                                    df['total_bill'],\n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "# Define classification columns\n",
    "categorical = list(X_train.select_dtypes('category').columns)\n",
    "print(f\"Categorical columns are: {categorical}\")\n",
    "\n",
    "# Define numeric columns\n",
    "numerical = list(X_train.select_dtypes('number').columns)\n",
    "print(f\"Numerical columns are: {numerical}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071ef88-9e45-476c-8ce3-1f2c01462cd9",
   "metadata": {},
   "source": [
    "<img src=\"data/columntransformer.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5c661b73-08aa-4836-a70f-58a3fbe23225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training data: [10.63 18.35 38.07 30.46]\n",
      "Predictions on test data: [18.35]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "# Define classification pipeline\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                     ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Define value pipeline\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Combined classification pipeline and numerical pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', cat_pipe, categorical),\n",
    "                                               ('num', num_pipe, numerical)])\n",
    "\n",
    "# Install transformer and training data estimator on the pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('model', LinearRegression())])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Forecast training data\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "print(f\"Predictions on training data: {y_train_pred}\")\n",
    "\n",
    "# Forecast test data\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(f\"Predictions on test data: {y_test_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c726162-0325-47c5-9bce-7438d5235f4f",
   "metadata": {},
   "source": [
    "<img src=\"data/featureunion.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7532a27e-9416-425e-b839-f6ccfdb61770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training data: [10.63 18.35 38.07 30.46]\n",
      "Predictions on test data: [18.35]\n"
     ]
    }
   ],
   "source": [
    "# Custom pipe\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select only specified columns.\"\"\"\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "# Define classification pipeline\n",
    "cat_pipe = Pipeline([('selector', ColumnSelector(categorical)),\n",
    "                     ('imputer', SimpleImputer(\n",
    "                         strategy='constant', fill_value='missing')),\n",
    "                     ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Define value pipeline\n",
    "num_pipe = Pipeline([('selector', ColumnSelector(numerical)),\n",
    "                     ('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Combined classification pipeline and numerical pipeline\n",
    "preprocessor = FeatureUnion(transformer_list=[('cat', cat_pipe),\n",
    "                                              ('num', num_pipe)])\n",
    "\n",
    "# Combined classification pipeline and numerical pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('model', LinearRegression())])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Forecast training data\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "print(f\"Predictions on training data: {y_train_pred}\")\n",
    "\n",
    "# Forecast test data\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(f\"Predictions on test data: {y_test_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043bced3-395c-4e60-9aca-a6144d12ce4c",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "1. Construir un FunctionalTransformer que elimine las filas duplicadas de una matriz\n",
    "2. Construir un StandardScalerCustom que resista el test check_estimator(StandardScalerCustom())\n",
    "3. Construir un Transformer que elimine las filas de un DataFrame que superen un porcentaje determinado de valores nulos o en las que la etiqueta tenga un valor nulo.\n",
    "4. Crear un transformer que registre la asimetría y la curtosis las columnas de la matriz\n",
    "5. Crear un transformer que convierta las columnas que tu le dices a categóricas sino lo son ya creando imputando el valor más frecuente en los valores nulos.\n",
    "6. Crear un transformer que elimine los datos que superen un número determinado de desviaciones típicas\n",
    "7. Crear un transformer que elimine un atributo numérico si tiene un valor único con un recuento superior a un porcentaje de los datos. Imagínate un atributo numérico en el que el 90% de los datos vale -1.0.\n",
    "8. Crear un transformer que cree una columna adicional con una categoría para cada valor único de un atributo numérico cuyo recuento sea muy superior a la media.$$\\begin{align}&\\frac{recuento}{n-recuento}\\times numuniq>6 \\\\ &numuniq*recuento>n+3\\sqrt{numuniq\\times\\left(\\sum_{i=1}^{numuniq} recuento_i²\\right)-n²}\\end{align}$$\n",
    "9. Crear un Transformer que opere sobre un dataframe para categorizar aquellas columnas cuya cantidad de valores únicos respecto al número total de datos es inferior a un umbral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1adc0-fe5f-4fb5-9f1e-30bce5f281b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
