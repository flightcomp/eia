{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012aa75c-cb96-4007-9919-95ecc7219014",
   "metadata": {},
   "source": [
    "# Torch vs Keras\n",
    "Lo primero que hay que decir es que Keras es sólo un wrapper. Puede utilizar como motor tensorflow, pytorch, cntk, theano, etc con solo hacer os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "En cuanto all MNIST dataset se puede descargar desde varias plataformas.\n",
    "1. Con sckitlearn mnist = sklearn.datasets.fetch_openml('mnist_784', version=1, as_frame=False) es un diccionario, X, y = mnist[\"data\"], mnist[\"target\"] crea una matriz X de 70000 filas por 784 columnas donde cada fila son los 28x28 pixeles en escala de 0 a 255\n",
    "2. (train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data() me devuelve train_images como un array unidimensional con todas las muestras seguidas unas detrás de otras\n",
    "3. content = requests.get(\"https://github.com/pytorch/tutorials/raw/main/_static/mnist.pkl.gz\").content descarga un array numpy serializado utilizando pickle que descomprimimos fácilmente con: with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9381c9-6ea6-4da9-b3df-a09c11e5516e",
   "metadata": {},
   "source": [
    "Quickstart\n",
    "==========\n",
    "\n",
    "This section runs through the API for common tasks in machine learning.\n",
    "Refer to the links in each section to dive deeper.\n",
    "\n",
    "Working with data\n",
    "-----------------\n",
    "\n",
    "PyTorch has two [primitives to work with\n",
    "data](https://pytorch.org/docs/stable/data.html):\n",
    "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
    "stores the samples and their corresponding labels, and `DataLoader`\n",
    "wraps an iterable around the `Dataset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88472460-50aa-49a1-b6cb-a8b2a0e167fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8c187-7f6d-465b-ac54-08cbafa58c96",
   "metadata": {},
   "source": [
    "Fíjate que se puede aplicar una transformada directamente antes de cargar los datos del fichero a una variable. Si el fichero ya está en disco no se descarga. En este caso lo que hacemos es crear un tensor a partir del array. Observa también que cada uno de los datasets es en realidad una tupla dato, etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d569205-9c95-495b-8a4b-f4d9f5bcc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processor\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomRotation(30),\n",
    "    #transforms.RandomResizedCrop(224),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "labels = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96819df-4020-4c64-86c7-0216be96146a",
   "metadata": {},
   "source": [
    "train_dataset y test_dataset son objetos de tipo Dataset una tupla de dos tensores o dos arrays, uno con los datos y el otro con las etiquetas. En este caso aplicamos una transformación a los datos leídos del fichero para convertir los array de numpy en un tensor de torch pero si ya tenemos los array de numpy y queremos crear un dataset a partir de ellos solo tendriamos que hacer:\n",
    "### Create torch Datasets from numpy arrays\n",
    ">train_dataset = torch.utils.data.TensorDataset(  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;torch.from_numpy(x_train), torch.from_numpy(y_train)  \n",
    ")  \n",
    "val_dataset = torch.utils.data.TensorDataset(  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;torch.from_numpy(x_val), torch.from_numpy(y_val)  \n",
    ")\n",
    "\n",
    "Fíjate en este ejemplo de un custom Dataset que obtiene las muestras de un csv (annotations_file) que tiene parejas: img_file_name, label y ficheros guardados en la carpeta img_dir con las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d00de94-53b2-496e-8fb0-0726c51b97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = decode_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d0ad3-49ee-466a-ab5d-c5afe85d044d",
   "metadata": {},
   "source": [
    "Es fácil visualizar el contenido de los datasets puesto que en realidad son dos tensores. Un tensor es algo parecido a una matriz pero si especificamos `required_grad=True` cada posición tendrá asociado también un gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b7631ba-3329-4084-8832-956f5202740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=mpl.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23e4a7-cb0a-4932-a8e6-5cbfa9b8e8ca",
   "metadata": {},
   "source": [
    "Ahora pasamos el dataset como argumento a un DataLoader que permitirá iterar sobre sus elementos, reordenarlos, dividirlos en bloques, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f85e494f-e937-4fc3-bbb5-3fe823598e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# make loaders for data\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {labels[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72638b-344f-41db-bdfd-6a606dcbdcc3",
   "metadata": {},
   "source": [
    "Ahora vamos a crear una red neuronal feedforward con 128, 64 y 10 nodos con activaciones relu desde cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf11ec86-45e9-49b7-8eb7-e3cb717ba21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, len(labels))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # En caso de recibir una matriz 28x28 me aseguro de aplanarla a 784\n",
    "        x = self.flatten(x)\n",
    "        # Los valores salientes todavía no son probabilidades\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe36e01-2f81-4a45-8160-e9c1d152c928",
   "metadata": {},
   "source": [
    "En lugar de usar Sequential __init__ define únicamente los pesos y forward se encarga de enlazar la salida de una capa con la otra interponiendo las activaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10e9e2a8-e567-4f9d-8d26-12f443bf1916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the PyTorch model class\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(784, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, len(labels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "model = SimpleNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519faec6-14e9-4e5c-b6f1-5e63af0a2338",
   "metadata": {},
   "source": [
    "Fíjate que la última capa tiene una activación lineal así que no me da probabilidades. Pero aún me falta definir la función de pérdida. Al definir la entropía cruzada como función de pérdida ya lo solucionamos porque CrossEntropyLoss en realidad lo que hace es aplicar una capa softmax. El algoritmo de optimización es el gradiente estocástico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "560012c3-d830-4273-b6bf-3f890cfb2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd60c0c-f223-4e08-bc1f-befaaa343e09",
   "metadata": {},
   "source": [
    "La función train lleva a cabo un epoch: Forward, Calculate loss, backpropagate loss, update weights, reset gradients\n",
    "Cada 100 iteraciones (minibatch) muestra resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346b6773-f3a1-4be4-be5a-8b43cca2bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward\n",
    "        pred = model(X)\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e909a79-4a7c-48c8-91b1-61390d9b5d68",
   "metadata": {},
   "source": [
    "Pero ya sabemos que el error en el train set no es lo importante sino el error en el test set. Fíjate que al evaluar no queremos que se calcule el gradiente y por eso usamos torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "928f1565-9b3d-40d5-afc8-ee8585c7487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    # Dos listas con el número de predicciones a cero\n",
    "    correct_pred = [0]*len(labels)\n",
    "    total_pred = [0]*len(labels)\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        # Para cada minibatch\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            # Para cada fila me da el índice de la columna con el valor más grande\n",
    "            predictions = outputs.argmax(1)\n",
    "            test_loss += loss_fn(outputs, y).item()\n",
    "            # Crea una lista de booleanos a True en los ejemplos en los que hay coincidencia y los pasa a float para sumarlos en un array de una posicion\n",
    "            # correct += (predictions == y).type(torch.float).sum().item()\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(y, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[label] += 1\n",
    "                # Acumula el número de ejemplos de cada etiqueta\n",
    "                total_pred[label] += 1\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct = sum(correct_pred)\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    # print accuracy for each class\n",
    "    for idx, correct_count in enumerate(correct_pred):\n",
    "        accuracy = 100 * float(correct_count) / total_pred[idx]\n",
    "        print(f'Accuracy for class: {labels[idx]:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8e985-b552-4735-9256-cd95b849bcd4",
   "metadata": {},
   "source": [
    "Si llamamos a la función que entrena ya la que evalua una seguida de otra para cada epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f42e505a-e514-4350-87f4-770fca69baf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.296434  [   32/60000]\n",
      "loss: 2.283089  [ 3232/60000]\n",
      "loss: 2.211408  [ 6432/60000]\n",
      "loss: 2.173044  [ 9632/60000]\n",
      "loss: 2.165689  [12832/60000]\n",
      "loss: 2.013448  [16032/60000]\n",
      "loss: 1.500696  [19232/60000]\n",
      "loss: 1.352682  [22432/60000]\n",
      "loss: 1.013193  [25632/60000]\n",
      "loss: 0.701278  [28832/60000]\n",
      "loss: 0.741578  [32032/60000]\n",
      "loss: 0.671140  [35232/60000]\n",
      "loss: 0.604895  [38432/60000]\n",
      "loss: 0.573912  [41632/60000]\n",
      "loss: 0.491948  [44832/60000]\n",
      "loss: 0.458725  [48032/60000]\n",
      "loss: 0.479735  [51232/60000]\n",
      "loss: 0.365209  [54432/60000]\n",
      "loss: 0.356890  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.446107 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.578468  [   32/60000]\n",
      "loss: 0.565349  [ 3232/60000]\n",
      "loss: 0.454970  [ 6432/60000]\n",
      "loss: 0.374543  [ 9632/60000]\n",
      "loss: 0.311543  [12832/60000]\n",
      "loss: 0.566003  [16032/60000]\n",
      "loss: 0.262239  [19232/60000]\n",
      "loss: 0.298342  [22432/60000]\n",
      "loss: 0.298904  [25632/60000]\n",
      "loss: 0.192156  [28832/60000]\n",
      "loss: 0.346645  [32032/60000]\n",
      "loss: 0.333504  [35232/60000]\n",
      "loss: 0.290292  [38432/60000]\n",
      "loss: 0.383589  [41632/60000]\n",
      "loss: 0.366061  [44832/60000]\n",
      "loss: 0.235002  [48032/60000]\n",
      "loss: 0.341681  [51232/60000]\n",
      "loss: 0.251543  [54432/60000]\n",
      "loss: 0.254645  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.331357 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c994bc-7109-4bf8-9211-e0bef89d9b98",
   "metadata": {},
   "source": [
    "Salvamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0849f870-fdd4-496b-a735-17d82e79b3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to data/model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to data/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77692c2d-b0de-4490-8c95-c9accd69a069",
   "metadata": {},
   "source": [
    "Y lo cargamos de nuevo. Para ello es necesario recrear la estructura del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b984d7e-d242-403a-bcc3-6ce1b11954e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"data/model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88f16571-f665-456f-966a-474ef560ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.331357 \n",
      "\n",
      "Accuracy for class: 0     is 97.8 %\n",
      "Accuracy for class: 1     is 98.1 %\n",
      "Accuracy for class: 2     is 84.7 %\n",
      "Accuracy for class: 3     is 88.9 %\n",
      "Accuracy for class: 4     is 92.3 %\n",
      "Accuracy for class: 5     is 87.2 %\n",
      "Accuracy for class: 6     is 91.9 %\n",
      "Accuracy for class: 7     is 86.4 %\n",
      "Accuracy for class: 8     is 82.1 %\n",
      "Accuracy for class: 9     is 91.5 %\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a7dd5-4ebd-4313-ae95-c73b087b0818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
